buildscript {
	repositories {
		mavenCentral()
	}

	dependencies {
		classpath "com.discord4j:discord4j-core:3.3.0-RC1"
	}
}
import discord4j.common.util.Snowflake
import discord4j.core.DiscordClient
import discord4j.core.event.domain.lifecycle.ReadyEvent
import discord4j.core.object.entity.channel.MessageChannel
import discord4j.core.object.entity.channel.ForumChannel
import discord4j.core.spec.ForumThreadMessageCreateSpec
import discord4j.core.spec.MessageCreateFields
import discord4j.core.spec.StartThreadInForumChannelSpec
import discord4j.discordjson.json.ChannelData
import discord4j.discordjson.json.ListThreadsData
import discord4j.rest.entity.RestChannel
import reactor.core.publisher.Flux
import reactor.core.publisher.Mono
import discord4j.core.object.ThreadListPart

import java.time.Instant
import java.util.concurrent.atomic.AtomicLong
import java.util.function.Function
import java.util.function.LongFunction
import java.util.function.ToLongFunction;
import java.util.zip.ZipEntry
import java.util.zip.ZipOutputStream

def discordFileLimit = 25600;

@FunctionalInterface
interface InstantFunction<R> {

    /**
     * Applies this function to the given argument.
     *
     * @param value the function argument
     * @return the function result
     */
    R apply(long s, long n)
}

@FunctionalInterface
public interface ToInstantFunction<T> {

    /**
     * Applies this function to the given argument.
     *
     * @param value the function argument
     * @return the function result
     */
    Instant applyAsInstant(T value);
}

class FixRestChannel {

    static <T> Comparator<T> comparingInstant(ToInstantFunction<? super T> keyExtractor) {
        Objects.requireNonNull(keyExtractor);
        return {c1, c2 -> (keyExtractor.applyAsInstant(c1) <=> keyExtractor.applyAsInstant(c2)) }
    }

    private static <T> Flux<T> paginate(final InstantFunction<Flux<T>> nextPage, final ToInstantFunction<T> keyExtractor,
                                        final Instant startAt, final boolean reverse) {

        final ToLongFunction<List<T>> updateLast = { list ->
            list.isEmpty() ? startAt : keyExtractor.applyAsInstant(list.get(list.size() - 1));
        }

        final Comparator<T> comparator = comparingInstant(keyExtractor);
        final AtomicLong previousStart = new AtomicLong(startAt.getEpochSecond());
        final AtomicLong previousStart_ns = new AtomicLong(startAt.getNano());

        return Flux.defer { nextPage.apply(previousStart.get(), previousStart_ns.get()) }
                .sort(reverse ? comparator.reversed() : comparator)
                .collectList()
                .doOnNext{list -> previousStart.set(updateLast.applyAsLong(list)) }
                .flatMapMany(Flux.&fromIterable)
                .repeat { previousStart.get() != startAt.getEpochSecond() && previousStart_ns.get() != startAt.getNano() };
    }

    private static Flux<ListThreadsData> listThreads(Function<Map<String, Object>, Mono<ListThreadsData>> doRequest) {
        ToInstantFunction<ListThreadsData> getLastThreadId = { response ->
            List<ChannelData> threads = response.threads();
            return threads.isEmpty() ? Long.MAX_VALUE : Snowflake.asLong(threads.get(threads.size() - 1).threadMetadata().get().archiveTimestamp());
        }
        final InstantFunction<Flux<ListThreadsData>> nextPage = { long s, long n ->
            final Map<String, Object> parameters = new HashMap<>(2);
            parameters.put("limit", 100);
            parameters.put("before", Instant.ofEpochSecond(s, n).toString());

            return doRequest.andThen{ it.flux() }.apply(parameters);
        }

        return paginate(nextPage, getLastThreadId, Instant.now(), true);
    }

    static Flux<ListThreadsData> getPublicArchivedThreads(RestChannel self) {
        listThreads{params -> self.restClient.getChannelService().listPublicArchivedThreads(self.@id, params)};
    }
}

RestChannel.mixin(FixRestChannel)

def splitFile(byte[] file, int maxSize=8192) {
	int parts = (int) Math.ceil((float) file.size() / (1024 * maxSize))
	ByteArrayInputStream[] sections = new ByteArrayInputStream[parts]
	printf("Parts: %s\n", parts)
	for (int i = 0; i < parts; i++) {
		int k = i*maxSize*1024
		byte[] partFile
		if (i == (parts - 1)) {
			partFile = new byte[file.size() - k]
		} else {
			partFile = new byte[maxSize*1024]
		}
		for (int j = 0; j < partFile.size(); j++) {
			partFile[j] = file[k + j]
		}
		printf("Part %s, Size %s\n", i, partFile.size())
		sections[i] = new ByteArrayInputStream(partFile)
	}
	return sections
}
task publishToDiscord() {
	doFirst {
        def files = new ArrayList<File>()
        def sections = new ArrayList<InputStream[]>()
        fileTree("../build/libs").each {
            if (it.size() > discordFileLimit*1024) {

                ByteArrayOutputStream baOS = new ByteArrayOutputStream()
                ZipOutputStream zOS = new ZipOutputStream(baOS)
                zOS.putNextEntry(new ZipEntry(it.name))
                zOS.write(it.readBytes())
                zOS.close()

                sections.add(splitFile(baOS.toByteArray(), discordFileLimit))
            } else {
                def section = new InputStream[1]
                section[0] = it.newInputStream()
                sections.add(section)
            }
            files.add(it)
        }
		def fullRef = System.getenv("WORKFLOW_GITHUB_REF").split("/", 2)
        def org = fullRef[0]
        def githubRef = fullRef[1]
        def thirdParty = org != 'ForgeEssentials'
		println("$org : $githubRef")
		final def token = System.getenv("DISCORD_TOKEN")
		final def client = DiscordClient.create(token)
        final def channelId;
        if (System.getenv("BUILD_NUMBER").startsWith("UNOFFICIAL")) {
            channelId = Long.parseLong(System.getenv("DEV_BUILD_CHANNEL_ID"))
        } else {
            channelId = Long.parseLong(System.getenv("RELEASE_CHANNEL_ID"))
        }
		println("ChannelId: $channelId")
		def login = client.withGateway { gateway ->
			gateway.on(ReadyEvent.class, { event ->
				def self = event.getSelf()
				printf("Logged in as %s#%s%n", self.getUsername(), self.getDiscriminator())

				println("Sending...")

				def tmp = gateway.getChannelById(Snowflake.of(channelId)).block()
                def channel = null

                def guildID = Snowflake.of(tmp.data.guildId().get())
                if (tmp instanceof ForumChannel) {
                    def threads = gateway.getGuildById(guildID).block().getActiveThreads().block().threads
                    def threadName = (thirdParty ? org + " -- " : "") + githubRef.split("/", 2)[1]
                    channel = threads.find{ it.name == threadName && it.parentId.get() == tmp.getId()}
                    if (channel == null) {

                        def aThreads = tmp.restChannel.getPublicArchivedThreads().map{data -> new ThreadListPart(gateway, data)}.blockFirst()
                        def found = aThreads.threads.findAll {it.name == threadName }.sort {a, b -> (b.archiveTimestamp <=> a.archiveTimestamp) }
                        if (found.size() > 0) {
                            channel = found.get(0)
                            channel.edit().withArchived(false).block()
                        }
                    }
                    if (channel == null) {
                        channel = tmp.startThread ( StartThreadInForumChannelSpec.builder()
                                .name(threadName)
                                .addAppliedTag(tmp.availableTags.find {it.name == "Build"}.id)
                                .message(ForumThreadMessageCreateSpec.builder()
                                        .content("Builds for Ref: $githubRef")
                                        .build())
                                .build()
                        ).block()
                    }
                } else {
                    channel = tmp as MessageChannel

                }
				println(channel.getType())
				Mono prev = null
				for (int i = 0; i < sections.size(); i++) {
                    boolean zipFiles = sections[i].size() > 1 || sections[i][0] instanceof ByteArrayInputStream
                    for (int j = 0; j < sections[i].size(); j++) {
                        String archiveName = files[i].name
                        if (zipFiles) {
                          archiveName += ".zip${sections[i].size() > 1 ? ".${String.format("%03d", j + 1)}" : ""}"
                        }

                        def content = "Forge Essentials build for${thirdParty ? " Third Party: `$org` --" : ""} Ref\\: `$githubRef` -- `$archiveName`"
                        println(content)
                        Mono cur = channel.createMessage()
                                .withContent(content)
                                .withFiles(MessageCreateFields.File.of(archiveName, sections[i][j])).then()
                        cur.doOnError({ error ->
                            println("Error sending Message")
                        })
                        if (prev != null) {
                            prev &= cur
                        } else {
                            prev = cur
                        }
                    }
				}
				return prev
			}).then()
		}
		login.subscribe()
		println("Message Sending...")
		Thread.sleep(15000)
		println("Complete")
	}
}
